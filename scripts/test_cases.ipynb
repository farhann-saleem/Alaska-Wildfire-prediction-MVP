{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wildfire Prediction Model - Test Cases\n",
    "## Comprehensive Testing Suite for MVP Demo\n",
    "\n",
    "This notebook contains multiple test cases to validate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n",
      "âœ“ Project root: G:\\UAAS\\Wildlife-prediction-try02\n"
     ]
    }
   ],
   "source": [
    "# TEST SETUP: Import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import precision_score, classification_report\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set paths\n",
    "PROJECT_ROOT = r\"G:\\UAAS\\Wildlife-prediction-try02\"\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "METADATA_CSV = os.path.join(PROJECT_ROOT, \"data\", \"patch_metadata.csv\")\n",
    "SENTINEL_TIF = os.path.join(DATA_DIR, \"s2_2021_06_input_10m.tif\")\n",
    "PATCH_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "print(f\"âœ“ Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Collecting rasterio\n",
      "  Downloading rasterio-1.4.4-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n",
      "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
      "Downloading rasterio-1.4.4-cp312-cp312-manylinux_2_28_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow \n",
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 1: Data Integrity Check\n",
    "Validates that data files exist and are accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST 1: Data Files Integrity\n",
      "============================================================\n",
      "âœ— MISSING: Patch Metadata CSV\n",
      "  Path: G:\\UAAS\\Wildlife-prediction-try02/data/patch_metadata.csv\n",
      "âœ— MISSING: Sentinel-2 GeoTIFF\n",
      "  Path: G:\\UAAS\\Wildlife-prediction-try02/data/raw/s2_2021_06_input_10m.tif\n",
      "\n",
      "FAILED âœ—\n"
     ]
    }
   ],
   "source": [
    "def test_data_files_exist():\n",
    "    \"\"\"TEST 1: Verify all required data files exist\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 1: Data Files Integrity\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    files_to_check = [\n",
    "        (METADATA_CSV, \"Patch Metadata CSV\"),\n",
    "        (SENTINEL_TIF, \"Sentinel-2 GeoTIFF\")\n",
    "    ]\n",
    "    \n",
    "    all_exist = True\n",
    "    for filepath, name in files_to_check:\n",
    "        exists = os.path.exists(filepath)\n",
    "        status = \"âœ“ EXISTS\" if exists else \"âœ— MISSING\"\n",
    "        print(f\"{status}: {name}\")\n",
    "        print(f\"  Path: {filepath}\")\n",
    "        all_exist = all_exist and exists\n",
    "    \n",
    "    # Check file sizes\n",
    "    if os.path.exists(METADATA_CSV):\n",
    "        size_mb = os.path.getsize(METADATA_CSV) / (1024*1024)\n",
    "        print(f\"  Size: {size_mb:.2f} MB\")\n",
    "    \n",
    "    if os.path.exists(SENTINEL_TIF):\n",
    "        size_mb = os.path.getsize(SENTINEL_TIF) / (1024*1024)\n",
    "        print(f\"  Size: {size_mb:.2f} MB\")\n",
    "    \n",
    "    return all_exist\n",
    "\n",
    "result_1 = test_data_files_exist()\n",
    "print(f\"\\n{'PASSED âœ“' if result_1 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 2: CSV Metadata Validation\n",
    "Checks CSV structure and label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_csv_metadata():\n",
    "    \"\"\"TEST 2: Validate CSV metadata structure and content\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 2: CSV Metadata Validation\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(METADATA_CSV)\n",
    "        print(f\"âœ“ CSV loaded successfully\")\n",
    "        print(f\"  Shape: {df.shape} (rows x columns)\")\n",
    "        print(f\"  Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        required_cols = ['burn_label']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if not missing_cols:\n",
    "            print(f\"âœ“ All required columns present\")\n",
    "        else:\n",
    "            print(f\"âœ— Missing columns: {missing_cols}\")\n",
    "            return False\n",
    "        \n",
    "        # Check for missing values\n",
    "        null_counts = df.isnull().sum()\n",
    "        if null_counts.sum() == 0:\n",
    "            print(f\"âœ“ No null values found\")\n",
    "        else:\n",
    "            print(f\"âš  Null values detected:\")\n",
    "            print(null_counts[null_counts > 0])\n",
    "        \n",
    "        # Label distribution\n",
    "        print(f\"\\n--- Label Distribution ---\")\n",
    "        label_dist = df['burn_label'].value_counts().sort_index()\n",
    "        for label, count in label_dist.items():\n",
    "            pct = (count / len(df)) * 100\n",
    "            print(f\"  Class {label}: {count:6d} ({pct:5.2f}%)\")\n",
    "        \n",
    "        # Class imbalance ratio\n",
    "        if len(label_dist) == 2:\n",
    "            ratio = label_dist[1] / label_dist[0]\n",
    "            print(f\"\\n  Imbalance Ratio (Burn/No-Burn): {ratio:.4f}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error reading CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "result_2 = test_csv_metadata()\n",
    "print(f\"\\n{'PASSED âœ“' if result_2 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 3: GeoTIFF Image Validation\n",
    "Checks raster dimensions, bands, and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_geotiff_integrity():\n",
    "    \"\"\"TEST 3: Validate GeoTIFF structure and properties\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 3: GeoTIFF Integrity Check\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(SENTINEL_TIF) as src:\n",
    "            print(f\"âœ“ GeoTIFF opened successfully\")\n",
    "            \n",
    "            # Basic properties\n",
    "            print(f\"\\n--- Raster Properties ---\")\n",
    "            print(f\"  Dimensions (W x H): {src.width} x {src.height}\")\n",
    "            print(f\"  Number of bands: {src.count}\")\n",
    "            print(f\"  Data type: {src.dtypes[0]}\")\n",
    "            print(f\"  CRS: {src.crs}\")\n",
    "            \n",
    "            # Expected for Sentinel-2 10m data\n",
    "            expected_bands = 3  # B2, B3, B4 (10m resolution)\n",
    "            if src.count == expected_bands:\n",
    "                print(f\"âœ“ Expected {expected_bands} bands (Sentinel-2)\")\n",
    "            else:\n",
    "                print(f\"âš  Expected {expected_bands} bands, got {src.count}\")\n",
    "            \n",
    "            # Read sample data\n",
    "            print(f\"\\n--- Data Statistics ---\")\n",
    "            for band in range(1, min(src.count+1, 4)):\n",
    "                data = src.read(band)\n",
    "                print(f\"  Band {band}:\")\n",
    "                print(f\"    Min: {data.min()}, Max: {data.max()}, Mean: {data.mean():.2f}\")\n",
    "                print(f\"    Nodata count: {np.sum(data == src.nodata)}\")\n",
    "            \n",
    "            return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error reading GeoTIFF: {e}\")\n",
    "        return False\n",
    "\n",
    "result_3 = test_geotiff_integrity()\n",
    "print(f\"\\n{'PASSED âœ“' if result_3 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 4: Patch Extraction & Normalization\n",
    "Tests the core data loading pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_patches_into_memory(metadata_path, sentinel_path, patch_size=64):\n",
    "    \"\"\"Load patches from GeoTIFF - core data loading function\"\"\"\n",
    "    print(\"Loading large GeoTIFF into memory and extracting patches...\")\n",
    "    \n",
    "    df = pd.read_csv(metadata_path)\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(sentinel_path) as src:\n",
    "            full_image_array = src.read()\n",
    "            img_width, img_height = src.width, src.height\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading TIF: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    full_image_array = np.transpose(full_image_array, (1, 2, 0))\n",
    "    \n",
    "    patch_list = []\n",
    "    label_list = []\n",
    "    patch_count = 0\n",
    "    nan_count = 0\n",
    "    \n",
    "    for y in range(0, img_height, patch_size):\n",
    "        for x in range(0, img_width, patch_size):\n",
    "            if x + patch_size > img_width or y + patch_size > img_height:\n",
    "                continue \n",
    "            \n",
    "            patch = full_image_array[y:y + patch_size, x:x + patch_size, :]\n",
    "            patch = patch / 10000.0  # Normalize Sentinel-2\n",
    "            \n",
    "            if np.isnan(patch).any():\n",
    "                nan_count += 1\n",
    "                patch_count += 1\n",
    "                continue\n",
    "            \n",
    "            patch_list.append(patch)\n",
    "            if patch_count < len(df):\n",
    "                label_list.append(df.iloc[patch_count]['burn_label'])\n",
    "            patch_count += 1\n",
    "    \n",
    "    X = np.stack(patch_list).astype(np.float32)\n",
    "    y = np.array(label_list)\n",
    "    \n",
    "    return X, y, df\n",
    "\n",
    "\n",
    "def test_patch_extraction():\n",
    "    \"\"\"TEST 4: Test patch extraction and normalization\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 4: Patch Extraction & Normalization\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        X, y, df = load_all_patches_into_memory(METADATA_CSV, SENTINEL_TIF, PATCH_SIZE)\n",
    "        \n",
    "        if X is None:\n",
    "            print(\"âœ— Failed to load patches\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"âœ“ Patches extracted successfully\")\n",
    "        print(f\"\\n--- Dataset Shape ---\")\n",
    "        print(f\"  X shape: {X.shape} (samples, height, width, channels)\")\n",
    "        print(f\"  y shape: {y.shape}\")\n",
    "        print(f\"  Total patches: {len(X)}\")\n",
    "        \n",
    "        # Data validation\n",
    "        print(f\"\\n--- Data Quality ---\")\n",
    "        print(f\"  X dtype: {X.dtype}\")\n",
    "        print(f\"  X min: {X.min():.6f}, max: {X.max():.6f}, mean: {X.mean():.6f}\")\n",
    "        print(f\"  NaN values: {np.isnan(X).sum()}\")\n",
    "        print(f\"  Inf values: {np.isinf(X).sum()}\")\n",
    "        \n",
    "        # Label check\n",
    "        print(f\"\\n--- Label Distribution ---\")\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        for label, count in zip(unique, counts):\n",
    "            pct = (count / len(y)) * 100\n",
    "            print(f\"  Class {label}: {count:6d} ({pct:5.2f}%)\")\n",
    "        \n",
    "        # Normalization check (should be between 0-1)\n",
    "        if X.max() <= 1.0 and X.min() >= 0.0:\n",
    "            print(f\"\\nâœ“ Data properly normalized (0-1 range)\")\n",
    "        else:\n",
    "            print(f\"âš  Data may not be properly normalized\")\n",
    "        \n",
    "        return True, X, y, df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False, None, None, None\n",
    "\n",
    "result_4, X, y, df = test_patch_extraction()\n",
    "print(f\"\\n{'PASSED âœ“' if result_4 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 5: Train-Test Split\n",
    "Validates stratified splitting preserves class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_test_split():\n",
    "    \"\"\"TEST 5: Validate train-test split stratification\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 5: Train-Test Split Validation\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if X is None or y is None:\n",
    "        print(\"âœ— No data loaded\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.25, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ Stratified split successful\")\n",
    "        print(f\"\\n--- Split Sizes ---\")\n",
    "        print(f\"  Training set: {len(X_train)} samples\")\n",
    "        print(f\"  Test set: {len(X_test)} samples\")\n",
    "        print(f\"  Total: {len(X_train) + len(X_test)} samples\")\n",
    "        \n",
    "        # Check class distribution\n",
    "        print(f\"\\n--- Class Distribution ---\")\n",
    "        print(f\"\\n  Original:\")\n",
    "        orig_unique, orig_counts = np.unique(y, return_counts=True)\n",
    "        for label, count in zip(orig_unique, orig_counts):\n",
    "            pct = (count / len(y)) * 100\n",
    "            print(f\"    Class {label}: {count:6d} ({pct:5.2f}%)\")\n",
    "        \n",
    "        print(f\"\\n  Training:\")\n",
    "        train_unique, train_counts = np.unique(y_train, return_counts=True)\n",
    "        for label, count in zip(train_unique, train_counts):\n",
    "            pct = (count / len(y_train)) * 100\n",
    "            print(f\"    Class {label}: {count:6d} ({pct:5.2f}%)\")\n",
    "        \n",
    "        print(f\"\\n  Test:\")\n",
    "        test_unique, test_counts = np.unique(y_test, return_counts=True)\n",
    "        for label, count in zip(test_unique, test_counts):\n",
    "            pct = (count / len(y_test)) * 100\n",
    "            print(f\"    Class {label}: {count:6d} ({pct:5.2f}%)\")\n",
    "        \n",
    "        return True, X_train, X_test, y_train, y_test\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        return False, None, None, None, None\n",
    "\n",
    "result_5, X_train, X_test, y_train, y_test = test_train_test_split()\n",
    "print(f\"\\n{'PASSED âœ“' if result_5 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 6: Model Architecture\n",
    "Tests that model can be created and compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_cnn(input_shape, num_classes=2):\n",
    "    \"\"\"Creates enhanced CNN with residual blocks\"\"\"\n",
    "    \n",
    "    def res_block(x, filters, kernel_size=3):\n",
    "        y = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(x)\n",
    "        y = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')(y)\n",
    "        x = tf.keras.layers.Conv2D(filters, 1)(x) \n",
    "        z = tf.keras.layers.Add()([x, y])\n",
    "        return tf.keras.layers.ReLU()(z)\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = res_block(x, 32)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = res_block(x, 64)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model_creation():\n",
    "    \"\"\"TEST 6: Test model creation and compilation\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 6: Model Architecture Validation\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        model = create_enhanced_cnn(input_shape=(PATCH_SIZE, PATCH_SIZE, 3))\n",
    "        print(f\"âœ“ Model created successfully\")\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(f\"âœ“ Model compiled successfully\")\n",
    "        \n",
    "        # Summary\n",
    "        print(f\"\\n--- Model Summary ---\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = model.count_params()\n",
    "        trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "        print(f\"\\n--- Parameters ---\")\n",
    "        print(f\"  Total parameters: {total_params:,}\")\n",
    "        print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        return True, model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False, None\n",
    "\n",
    "result_6, model = test_model_creation()\n",
    "print(f\"\\n{'PASSED âœ“' if result_6 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 7: Forward Pass (Inference)\n",
    "Tests that model can process sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass():\n",
    "    \"\"\"TEST 7: Test model forward pass with sample data\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 7: Forward Pass (Inference) Test\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if model is None or X_test is None:\n",
    "        print(\"âœ— Model or data not loaded\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Test single sample\n",
    "        sample = X_test[0:1]  # Shape: (1, 64, 64, 3)\n",
    "        print(f\"âœ“ Testing with single sample\")\n",
    "        print(f\"  Input shape: {sample.shape}\")\n",
    "        \n",
    "        predictions = model.predict(sample, verbose=0)\n",
    "        print(f\"\\nâœ“ Forward pass successful\")\n",
    "        print(f\"  Output shape: {predictions.shape}\")\n",
    "        print(f\"  Probabilities: {predictions[0]}\")\n",
    "        print(f\"  Predicted class: {np.argmax(predictions[0])}\")\n",
    "        \n",
    "        # Test batch\n",
    "        batch = X_test[0:32]\n",
    "        print(f\"\\nâœ“ Testing with batch of 32 samples\")\n",
    "        print(f\"  Input shape: {batch.shape}\")\n",
    "        \n",
    "        predictions_batch = model.predict(batch, verbose=0)\n",
    "        print(f\"\\nâœ“ Batch prediction successful\")\n",
    "        print(f\"  Output shape: {predictions_batch.shape}\")\n",
    "        print(f\"  Prediction range: [{predictions_batch.min():.4f}, {predictions_batch.max():.4f}]\")\n",
    "        \n",
    "        # Check probability sums to 1\n",
    "        sums = predictions_batch.sum(axis=1)\n",
    "        if np.allclose(sums, 1.0):\n",
    "            print(f\"âœ“ Probabilities correctly sum to 1.0\")\n",
    "        else:\n",
    "            print(f\"âš  Probability sums: min={sums.min():.6f}, max={sums.max():.6f}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "result_7 = test_forward_pass()\n",
    "print(f\"\\n{'PASSED âœ“' if result_7 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 8: Mini Training (Overfitting Test)\n",
    "Tests that model can train on a small subset (should overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mini_training():\n",
    "    \"\"\"TEST 8: Test training on small subset (should overfit quickly)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 8: Mini Training Test (Overfitting Expected)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if model is None or X_train is None:\n",
    "        print(\"âœ— Model or data not loaded\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Use only 256 samples for quick test\n",
    "        X_mini = X_train[0:256]\n",
    "        y_mini = y_train[0:256]\n",
    "        \n",
    "        print(f\"âœ“ Training on mini dataset: {len(X_mini)} samples\")\n",
    "        print(f\"  Class distribution: {np.bincount(y_mini)}\")\n",
    "        \n",
    "        # Create fresh model\n",
    "        model_mini = create_enhanced_cnn(input_shape=(PATCH_SIZE, PATCH_SIZE, 3))\n",
    "        model_mini.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train for 3 epochs\n",
    "        print(f\"\\n--- Training Progress ---\")\n",
    "        history = model_mini.fit(\n",
    "            X_mini, y_mini,\n",
    "            epochs=3,\n",
    "            batch_size=32,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ“ Training completed\")\n",
    "        \n",
    "        # Check if loss decreased (overfitting)\n",
    "        loss_prog = history.history['loss']\n",
    "        print(f\"\\n--- Loss Progression ---\")\n",
    "        for epoch, loss in enumerate(loss_prog, 1):\n",
    "            print(f\"  Epoch {epoch}: {loss:.4f}\")\n",
    "        \n",
    "        if loss_prog[-1] < loss_prog[0]:\n",
    "            print(f\"\\nâœ“ Loss decreased (model is learning)\")\n",
    "        else:\n",
    "            print(f\"âš  Loss did not decrease significantly\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "result_8 = test_mini_training()\n",
    "print(f\"\\n{'PASSED âœ“' if result_8 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 9: Metrics Computation\n",
    "Tests evaluation metrics on sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics_computation():\n",
    "    \"\"\"TEST 9: Test metric computation\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 9: Metrics Computation Test\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if model is None or X_test is None:\n",
    "        print(\"âœ— Model or data not loaded\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Get predictions on test set\n",
    "        print(f\"âœ“ Computing predictions on test set ({len(X_test)} samples)\")\n",
    "        y_pred_proba = model.predict(X_test, verbose=0)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "        print(f\"âœ“ Predictions computed\")\n",
    "        print(f\"  Predicted class distribution: {np.bincount(y_pred)}\")\n",
    "        print(f\"  True class distribution: {np.bincount(y_test)}\")\n",
    "        \n",
    "        # Compute metrics\n",
    "        print(f\"\\n--- Classification Metrics ---\")\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"\\n--- Confusion Matrix ---\")\n",
    "        print(f\"  True Negatives (TN): {cm[0,0]}\")\n",
    "        print(f\"  False Positives (FP): {cm[0,1]}\")\n",
    "        print(f\"  False Negatives (FN): {cm[1,0]}\")\n",
    "        print(f\"  True Positives (TP): {cm[1,1]}\")\n",
    "        \n",
    "        # Classification report\n",
    "        print(f\"\\n--- Detailed Classification Report ---\")\n",
    "        print(classification_report(y_test, y_pred, target_names=['No-Burn', 'Burn']))\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "result_9 = test_metrics_computation()\n",
    "print(f\"\\n{'PASSED âœ“' if result_9 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST 10: Visualization\n",
    "Tests plotting and visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_visualizations():\n",
    "    \"\"\"TEST 10: Test visualization functions\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 10: Visualization Test\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if X_test is None or y_test is None:\n",
    "        print(\"âœ— Data not loaded\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        fig.suptitle('Wildfire Prediction - Test Visualizations', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # 1. Sample patches\n",
    "        print(f\"âœ“ Plotting sample patches...\")\n",
    "        for i in range(2):\n",
    "            # Display patch as RGB (normalize to 0-1)\n",
    "            patch = X_test[i]\n",
    "            patch_rgb = np.clip(patch * 3, 0, 1)  # Scale for visibility\n",
    "            axes[0, i].imshow(patch_rgb)\n",
    "            axes[0, i].set_title(f'Patch {i} (Label: {y_test[i]})')\n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # 2. Class distribution\n",
    "        print(f\"âœ“ Plotting class distribution...\")\n",
    "        classes = ['No-Burn', 'Burn']\n",
    "        class_counts = np.bincount(y_test)\n",
    "        axes[1, 0].bar(classes, class_counts, color=['green', 'red'])\n",
    "        axes[1, 0].set_title('Test Set Class Distribution')\n",
    "        axes[1, 0].set_ylabel('Count')\n",
    "        for j, v in enumerate(class_counts):\n",
    "            axes[1, 0].text(j, v, str(v), ha='center', va='bottom')\n",
    "        \n",
    "        # 3. Probability distribution\n",
    "        print(f\"âœ“ Plotting prediction probabilities...\")\n",
    "        if model is not None:\n",
    "            y_pred_proba = model.predict(X_test[:1000], verbose=0)  # First 1000 for speed\n",
    "            axes[1, 1].hist(y_pred_proba[:, 1], bins=30, edgecolor='black', alpha=0.7)\n",
    "            axes[1, 1].set_title('Predicted Probability Distribution (Class 1)')\n",
    "            axes[1, 1].set_xlabel('Probability')\n",
    "            axes[1, 1].set_ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(PROJECT_ROOT, 'test_visualizations.png'), dpi=100, bbox_inches='tight')\n",
    "        print(f\"\\nâœ“ Visualizations saved to 'test_visualizations.png'\")\n",
    "        plt.show()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "result_10 = test_visualizations()\n",
    "print(f\"\\n{'PASSED âœ“' if result_10 else 'FAILED âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TEST SUMMARY\n",
    "Summary of all test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all tests\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tests = [\n",
    "    (\"TEST 1\", \"Data Files Integrity\", result_1),\n",
    "    (\"TEST 2\", \"CSV Metadata Validation\", result_2),\n",
    "    (\"TEST 3\", \"GeoTIFF Integrity Check\", result_3),\n",
    "    (\"TEST 4\", \"Patch Extraction & Normalization\", result_4),\n",
    "    (\"TEST 5\", \"Train-Test Split Validation\", result_5),\n",
    "    (\"TEST 6\", \"Model Architecture Validation\", result_6),\n",
    "    (\"TEST 7\", \"Forward Pass (Inference) Test\", result_7),\n",
    "    (\"TEST 8\", \"Mini Training Test\", result_8),\n",
    "    (\"TEST 9\", \"Metrics Computation Test\", result_9),\n",
    "    (\"TEST 10\", \"Visualization Test\", result_10),\n",
    "]\n",
    "\n",
    "passed = 0\n",
    "failed = 0\n",
    "\n",
    "print(f\"\\n{'Test':<10} {'Description':<40} {'Result':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for test_id, description, result in tests:\n",
    "    status = \"âœ“ PASSED\" if result else \"âœ— FAILED\"\n",
    "    if result:\n",
    "        passed += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "    print(f\"{test_id:<10} {description:<40} {status:<15}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nTotal: {passed} PASSED, {failed} FAILED out of 10 tests\")\n",
    "print(f\"Success Rate: {(passed/10)*100:.0f}%\")\n",
    "\n",
    "if passed == 10:\n",
    "    print(\"\\nðŸŽ‰ ALL TESTS PASSED! MVP pipeline is working.\")\n",
    "elif passed >= 7:\n",
    "    print(\"\\nâœ“ Most tests passed. Minor issues to address.\")\n",
    "else:\n",
    "    print(\"\\nâš  Multiple test failures. Review errors above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes for GSOC Demo\n",
    "\n",
    "**What this test suite validates:**\n",
    "\n",
    "1. âœ“ **Data Pipeline**: GEE export â†’ CSV metadata â†’ TIF loading\n",
    "2. âœ“ **Data Quality**: Normalization, NaN handling, class distribution\n",
    "3. âœ“ **Model Architecture**: CNN with residual blocks compiles correctly\n",
    "4. âœ“ **Training Loop**: Forward pass, loss computation, gradient updates\n",
    "5. âœ“ **Evaluation**: Metrics (Accuracy, F1, Recall, Precision)\n",
    "6. âœ“ **Reproducibility**: Stratified splits, random seeds, version control\n",
    "\n",
    "**Next Steps:**\n",
    "- [ ] Run full training (20 epochs) on Colab with T4 GPU\n",
    "- [ ] Implement Focal Loss for class imbalance\n",
    "- [ ] Add SMOTE oversampling\n",
    "- [ ] Compare with Random Forest baseline\n",
    "- [ ] Create PR to original repository\n",
    "\n",
    "**Known Issues to Address:**\n",
    "- F1 score = 0 (class imbalance â†’ implement weighted loss)\n",
    "- Model predicts all samples as negative class (threshold tuning needed)\n",
    "- Some NaN patches detected (filtering is working correctly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
